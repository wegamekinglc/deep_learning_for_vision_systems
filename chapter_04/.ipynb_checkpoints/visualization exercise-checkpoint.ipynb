{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a toy dataset of only two features and four label classes\n",
    "X, y = make_blobs(n_samples=1000, centers=4, n_features=2, cluster_std=2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 0, 1, 2, 3, 2, 1, 0, 1, 0, 0, 2, 2, 3, 2, 1, 3, 0,\n",
       "       0, 3, 1, 3, 3, 3, 0, 2, 0, 0, 2, 3, 1, 0, 1, 2, 2, 1, 3, 3, 1, 2,\n",
       "       3, 0, 0, 1, 1, 0, 0, 3, 0, 3, 2, 3, 3, 0, 2, 1, 3, 1, 3, 0, 1, 3,\n",
       "       0, 1, 3, 0, 2, 1, 3, 3, 2, 2, 1, 1, 3, 2, 3, 1, 2, 2, 0, 2, 3, 3,\n",
       "       1, 2, 3, 0, 2, 0, 1, 2, 2, 0, 3, 0, 3, 3, 3, 1, 1, 2, 2, 1, 0, 3,\n",
       "       0, 3, 1, 3, 0, 0, 0, 0, 2, 2, 0, 3, 0, 2, 1, 2, 3, 0, 1, 0, 2, 0,\n",
       "       0, 0, 1, 0, 3, 2, 1, 1, 3, 1, 0, 2, 3, 3, 1, 1, 1, 3, 1, 1, 3, 0,\n",
       "       1, 1, 1, 3, 2, 2, 0, 2, 1, 2, 0, 2, 0, 1, 1, 2, 1, 3, 3, 0, 3, 2,\n",
       "       1, 2, 2, 3, 3, 0, 2, 2, 2, 1, 2, 1, 0, 0, 1, 3, 2, 2, 1, 0, 3, 2,\n",
       "       3, 3, 3, 3, 3, 2, 3, 1, 2, 3, 0, 2, 0, 2, 3, 3, 0, 3, 0, 3, 0, 3,\n",
       "       2, 3, 3, 0, 2, 1, 1, 1, 3, 3, 2, 1, 3, 3, 3, 3, 2, 0, 2, 3, 1, 1,\n",
       "       3, 2, 0, 0, 2, 0, 2, 1, 0, 3, 1, 1, 1, 0, 1, 2, 3, 1, 2, 1, 2, 2,\n",
       "       2, 0, 2, 0, 3, 2, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 3, 2, 3, 1, 3, 0,\n",
       "       2, 0, 2, 3, 2, 1, 3, 1, 2, 1, 2, 0, 3, 0, 3, 0, 2, 1, 1, 2, 0, 1,\n",
       "       1, 0, 2, 3, 3, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 0, 1, 3, 2, 1, 1, 1,\n",
       "       2, 1, 1, 3, 3, 3, 0, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 3, 2, 0, 2, 1,\n",
       "       1, 0, 2, 1, 2, 1, 0, 0, 1, 3, 3, 0, 1, 2, 2, 0, 0, 0, 3, 2, 0, 1,\n",
       "       0, 3, 3, 2, 3, 0, 2, 0, 3, 3, 3, 1, 2, 0, 3, 1, 2, 3, 3, 0, 0, 2,\n",
       "       0, 3, 3, 1, 3, 1, 0, 2, 3, 1, 1, 1, 1, 0, 0, 1, 3, 2, 2, 3, 0, 2,\n",
       "       2, 0, 2, 2, 2, 3, 0, 0, 0, 3, 1, 1, 3, 2, 1, 2, 2, 1, 1, 0, 3, 2,\n",
       "       0, 3, 1, 2, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1, 3, 1, 1, 1, 0, 3, 2,\n",
       "       2, 2, 2, 0, 0, 3, 2, 2, 0, 3, 0, 0, 2, 3, 0, 1, 1, 0, 3, 1, 0, 3,\n",
       "       2, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 3, 1, 1, 1, 1, 1, 0,\n",
       "       0, 2, 1, 3, 1, 0, 3, 0, 0, 3, 2, 1, 1, 0, 3, 2, 2, 1, 3, 2, 1, 1,\n",
       "       3, 2, 3, 1, 3, 2, 3, 2, 2, 3, 1, 2, 0, 3, 2, 2, 0, 0, 3, 3, 2, 2,\n",
       "       2, 1, 3, 0, 2, 2, 3, 2, 3, 2, 3, 0, 3, 1, 0, 1, 1, 3, 3, 3, 2, 3,\n",
       "       3, 1, 0, 2, 3, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 3, 1, 1, 3, 3, 2, 1,\n",
       "       2, 3, 3, 3, 1, 3, 3, 2, 0, 2, 1, 0, 1, 3, 0, 2, 2, 2, 3, 3, 0, 0,\n",
       "       3, 0, 2, 2, 0, 0, 0, 3, 3, 1, 1, 3, 3, 1, 0, 3, 0, 1, 1, 0, 2, 3,\n",
       "       0, 3, 1, 3, 0, 2, 1, 3, 3, 3, 0, 1, 3, 0, 0, 2, 3, 2, 0, 3, 1, 2,\n",
       "       3, 0, 3, 3, 0, 1, 2, 1, 2, 2, 2, 1, 3, 2, 2, 1, 0, 3, 2, 3, 2, 1,\n",
       "       1, 2, 0, 3, 3, 3, 1, 1, 1, 2, 1, 0, 3, 2, 0, 1, 2, 1, 0, 0, 1, 1,\n",
       "       1, 0, 3, 3, 0, 1, 1, 1, 2, 0, 3, 2, 1, 2, 1, 2, 0, 1, 1, 1, 0, 2,\n",
       "       2, 3, 1, 2, 1, 3, 2, 3, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 1, 0, 3,\n",
       "       0, 0, 2, 0, 3, 1, 0, 3, 1, 2, 1, 1, 0, 1, 2, 2, 1, 1, 3, 1, 2, 1,\n",
       "       0, 0, 3, 2, 1, 0, 1, 0, 3, 0, 3, 0, 0, 3, 1, 1, 3, 2, 3, 1, 2, 3,\n",
       "       1, 2, 3, 2, 2, 3, 1, 1, 1, 3, 0, 0, 2, 2, 1, 1, 0, 3, 2, 0, 0, 1,\n",
       "       3, 2, 2, 0, 3, 3, 3, 0, 3, 2, 2, 2, 0, 2, 2, 1, 1, 3, 2, 0, 0, 3,\n",
       "       2, 2, 3, 0, 2, 0, 1, 3, 2, 1, 1, 1, 2, 3, 0, 3, 3, 2, 0, 2, 1, 3,\n",
       "       0, 3, 2, 0, 1, 0, 1, 2, 2, 1, 1, 2, 0, 1, 0, 2, 1, 3, 2, 2, 2, 3,\n",
       "       3, 0, 0, 1, 3, 1, 1, 1, 2, 2, 2, 1, 0, 0, 3, 2, 2, 3, 3, 1, 0, 2,\n",
       "       1, 3, 3, 2, 0, 0, 2, 3, 1, 0, 2, 3, 0, 1, 2, 3, 0, 3, 1, 2, 2, 2,\n",
       "       0, 0, 1, 0, 0, 3, 2, 2, 0, 3, 1, 3, 2, 0, 0, 1, 2, 3, 3, 2, 1, 3,\n",
       "       0, 1, 1, 0, 0, 1, 3, 2, 1, 1, 3, 3, 2, 0, 3, 0, 3, 2, 2, 0, 3, 3,\n",
       "       1, 0, 0, 2, 1, 3, 3, 0, 2, 3, 1, 0, 1, 1, 2, 0, 3, 2, 0, 1, 0, 0,\n",
       "       3, 0, 1, 0, 3, 1, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the label (y) before one-hot encoding\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode output variable\n",
    "y = to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "# split into 80% training data and 20% test data \n",
    "# note that we did not create a validation dataset in this example for simplicity\n",
    "n_train = 800\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                75        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 104       \n",
      "=================================================================\n",
      "Total params: 179\n",
      "Trainable params: 179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# develop the baseline model architecture\n",
    "# here we are building a very simple, two-layer network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax')) # four hidden units because we have 4 label classes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/500\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.5767 - accuracy: 0.5312 - val_loss: 1.1619 - val_accuracy: 0.5250\n",
      "Epoch 2/500\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.9202 - accuracy: 0.5663 - val_loss: 0.7882 - val_accuracy: 0.6100\n",
      "Epoch 3/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.7601 - accuracy: 0.6187 - val_loss: 0.7374 - val_accuracy: 0.6200\n",
      "Epoch 4/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.7102 - accuracy: 0.6475 - val_loss: 0.7033 - val_accuracy: 0.6500\n",
      "Epoch 5/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.6746 - accuracy: 0.6875 - val_loss: 0.6769 - val_accuracy: 0.6900\n",
      "Epoch 6/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.6460 - accuracy: 0.7075 - val_loss: 0.6561 - val_accuracy: 0.7100\n",
      "Epoch 7/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.6243 - accuracy: 0.7262 - val_loss: 0.6391 - val_accuracy: 0.7250\n",
      "Epoch 8/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.6050 - accuracy: 0.7375 - val_loss: 0.6242 - val_accuracy: 0.7300\n",
      "Epoch 9/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.5886 - accuracy: 0.7500 - val_loss: 0.6120 - val_accuracy: 0.7200\n",
      "Epoch 10/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.5740 - accuracy: 0.7600 - val_loss: 0.6017 - val_accuracy: 0.7300\n",
      "Epoch 11/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.5611 - accuracy: 0.7613 - val_loss: 0.5910 - val_accuracy: 0.7450\n",
      "Epoch 12/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.5491 - accuracy: 0.7675 - val_loss: 0.5826 - val_accuracy: 0.7400\n",
      "Epoch 13/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.5400 - accuracy: 0.7800 - val_loss: 0.5770 - val_accuracy: 0.7600\n",
      "Epoch 14/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.5299 - accuracy: 0.7763 - val_loss: 0.5654 - val_accuracy: 0.7600\n",
      "Epoch 15/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.5211 - accuracy: 0.7862 - val_loss: 0.5588 - val_accuracy: 0.7500\n",
      "Epoch 16/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.5120 - accuracy: 0.7850 - val_loss: 0.5527 - val_accuracy: 0.7600\n",
      "Epoch 17/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.5040 - accuracy: 0.7962 - val_loss: 0.5467 - val_accuracy: 0.7600\n",
      "Epoch 18/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4960 - accuracy: 0.7987 - val_loss: 0.5399 - val_accuracy: 0.7650\n",
      "Epoch 19/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4895 - accuracy: 0.8037 - val_loss: 0.5340 - val_accuracy: 0.7750\n",
      "Epoch 20/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.4822 - accuracy: 0.8000 - val_loss: 0.5288 - val_accuracy: 0.7750\n",
      "Epoch 21/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.4758 - accuracy: 0.8087 - val_loss: 0.5256 - val_accuracy: 0.7800\n",
      "Epoch 22/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.4703 - accuracy: 0.8100 - val_loss: 0.5171 - val_accuracy: 0.7950\n",
      "Epoch 23/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4646 - accuracy: 0.8100 - val_loss: 0.5122 - val_accuracy: 0.8050\n",
      "Epoch 24/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4586 - accuracy: 0.8112 - val_loss: 0.5071 - val_accuracy: 0.8050\n",
      "Epoch 25/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.4545 - accuracy: 0.8138 - val_loss: 0.5034 - val_accuracy: 0.8050\n",
      "Epoch 26/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4481 - accuracy: 0.8175 - val_loss: 0.4976 - val_accuracy: 0.8050\n",
      "Epoch 27/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4436 - accuracy: 0.8175 - val_loss: 0.4921 - val_accuracy: 0.8100\n",
      "Epoch 28/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.4379 - accuracy: 0.8200 - val_loss: 0.4882 - val_accuracy: 0.8050\n",
      "Epoch 29/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.4335 - accuracy: 0.8263 - val_loss: 0.4848 - val_accuracy: 0.8150\n",
      "Epoch 30/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.4290 - accuracy: 0.8300 - val_loss: 0.4787 - val_accuracy: 0.8150\n",
      "Epoch 31/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.4247 - accuracy: 0.8263 - val_loss: 0.4749 - val_accuracy: 0.8100\n",
      "Epoch 32/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.4214 - accuracy: 0.8313 - val_loss: 0.4724 - val_accuracy: 0.8200\n",
      "Epoch 33/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4180 - accuracy: 0.8288 - val_loss: 0.4691 - val_accuracy: 0.8200\n",
      "Epoch 34/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4144 - accuracy: 0.8325 - val_loss: 0.4666 - val_accuracy: 0.8200\n",
      "Epoch 35/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.4100 - accuracy: 0.8363 - val_loss: 0.4615 - val_accuracy: 0.8250\n",
      "Epoch 36/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4069 - accuracy: 0.8325 - val_loss: 0.4572 - val_accuracy: 0.8200\n",
      "Epoch 37/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.4039 - accuracy: 0.8375 - val_loss: 0.4545 - val_accuracy: 0.8200\n",
      "Epoch 38/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.4017 - accuracy: 0.8350 - val_loss: 0.4503 - val_accuracy: 0.8250\n",
      "Epoch 39/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3993 - accuracy: 0.8375 - val_loss: 0.4477 - val_accuracy: 0.8300\n",
      "Epoch 40/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3971 - accuracy: 0.8288 - val_loss: 0.4467 - val_accuracy: 0.8250\n",
      "Epoch 41/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3933 - accuracy: 0.8462 - val_loss: 0.4426 - val_accuracy: 0.8150\n",
      "Epoch 42/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3915 - accuracy: 0.8363 - val_loss: 0.4413 - val_accuracy: 0.8200\n",
      "Epoch 43/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3900 - accuracy: 0.8438 - val_loss: 0.4371 - val_accuracy: 0.8200\n",
      "Epoch 44/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3873 - accuracy: 0.8400 - val_loss: 0.4360 - val_accuracy: 0.8250\n",
      "Epoch 45/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3852 - accuracy: 0.8438 - val_loss: 0.4342 - val_accuracy: 0.8200\n",
      "Epoch 46/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3832 - accuracy: 0.8462 - val_loss: 0.4298 - val_accuracy: 0.8250\n",
      "Epoch 47/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3825 - accuracy: 0.8487 - val_loss: 0.4298 - val_accuracy: 0.8250\n",
      "Epoch 48/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3808 - accuracy: 0.8462 - val_loss: 0.4272 - val_accuracy: 0.8250\n",
      "Epoch 49/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3805 - accuracy: 0.8450 - val_loss: 0.4279 - val_accuracy: 0.8250\n",
      "Epoch 50/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3778 - accuracy: 0.8487 - val_loss: 0.4247 - val_accuracy: 0.8300\n",
      "Epoch 51/500\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.3775 - accuracy: 0.8438 - val_loss: 0.4223 - val_accuracy: 0.8250\n",
      "Epoch 52/500\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3758 - accuracy: 0.8462 - val_loss: 0.4220 - val_accuracy: 0.8300\n",
      "Epoch 53/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3747 - accuracy: 0.8500 - val_loss: 0.4209 - val_accuracy: 0.8300\n",
      "Epoch 54/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3734 - accuracy: 0.8537 - val_loss: 0.4188 - val_accuracy: 0.8300\n",
      "Epoch 55/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3722 - accuracy: 0.8462 - val_loss: 0.4186 - val_accuracy: 0.8300\n",
      "Epoch 56/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3714 - accuracy: 0.8500 - val_loss: 0.4177 - val_accuracy: 0.8300\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 24us/step - loss: 0.3704 - accuracy: 0.8487 - val_loss: 0.4158 - val_accuracy: 0.8300\n",
      "Epoch 58/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3698 - accuracy: 0.8487 - val_loss: 0.4152 - val_accuracy: 0.8350\n",
      "Epoch 59/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3685 - accuracy: 0.8475 - val_loss: 0.4150 - val_accuracy: 0.8250\n",
      "Epoch 60/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3687 - accuracy: 0.8512 - val_loss: 0.4136 - val_accuracy: 0.8300\n",
      "Epoch 61/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3688 - accuracy: 0.8512 - val_loss: 0.4142 - val_accuracy: 0.8250\n",
      "Epoch 62/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3678 - accuracy: 0.8500 - val_loss: 0.4119 - val_accuracy: 0.8350\n",
      "Epoch 63/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3669 - accuracy: 0.8525 - val_loss: 0.4122 - val_accuracy: 0.8250\n",
      "Epoch 64/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3665 - accuracy: 0.8512 - val_loss: 0.4090 - val_accuracy: 0.8300\n",
      "Epoch 65/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3652 - accuracy: 0.8487 - val_loss: 0.4110 - val_accuracy: 0.8350\n",
      "Epoch 66/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3650 - accuracy: 0.8487 - val_loss: 0.4093 - val_accuracy: 0.8300\n",
      "Epoch 67/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3644 - accuracy: 0.8512 - val_loss: 0.4088 - val_accuracy: 0.8300\n",
      "Epoch 68/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3645 - accuracy: 0.8450 - val_loss: 0.4060 - val_accuracy: 0.8350\n",
      "Epoch 69/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3632 - accuracy: 0.8525 - val_loss: 0.4068 - val_accuracy: 0.8350\n",
      "Epoch 70/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3643 - accuracy: 0.8500 - val_loss: 0.4057 - val_accuracy: 0.8350\n",
      "Epoch 71/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3636 - accuracy: 0.8525 - val_loss: 0.4056 - val_accuracy: 0.8350\n",
      "Epoch 72/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3619 - accuracy: 0.8500 - val_loss: 0.4055 - val_accuracy: 0.8350\n",
      "Epoch 73/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3619 - accuracy: 0.8537 - val_loss: 0.4053 - val_accuracy: 0.8350\n",
      "Epoch 74/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3619 - accuracy: 0.8512 - val_loss: 0.4056 - val_accuracy: 0.8300\n",
      "Epoch 75/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3617 - accuracy: 0.8525 - val_loss: 0.4039 - val_accuracy: 0.8350\n",
      "Epoch 76/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3615 - accuracy: 0.8525 - val_loss: 0.4049 - val_accuracy: 0.8300\n",
      "Epoch 77/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3609 - accuracy: 0.8512 - val_loss: 0.4030 - val_accuracy: 0.8350\n",
      "Epoch 78/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3615 - accuracy: 0.8487 - val_loss: 0.4052 - val_accuracy: 0.8400\n",
      "Epoch 79/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3611 - accuracy: 0.8487 - val_loss: 0.4036 - val_accuracy: 0.8350\n",
      "Epoch 80/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3595 - accuracy: 0.8500 - val_loss: 0.4031 - val_accuracy: 0.8350\n",
      "Epoch 81/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3596 - accuracy: 0.8500 - val_loss: 0.4032 - val_accuracy: 0.8350\n",
      "Epoch 82/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3595 - accuracy: 0.8500 - val_loss: 0.4012 - val_accuracy: 0.8350\n",
      "Epoch 83/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3588 - accuracy: 0.8525 - val_loss: 0.4029 - val_accuracy: 0.8350\n",
      "Epoch 84/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3584 - accuracy: 0.8525 - val_loss: 0.4022 - val_accuracy: 0.8350\n",
      "Epoch 85/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3591 - accuracy: 0.8500 - val_loss: 0.4024 - val_accuracy: 0.8350\n",
      "Epoch 86/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3586 - accuracy: 0.8537 - val_loss: 0.4004 - val_accuracy: 0.8400\n",
      "Epoch 87/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3590 - accuracy: 0.8525 - val_loss: 0.4026 - val_accuracy: 0.8350\n",
      "Epoch 88/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3579 - accuracy: 0.8500 - val_loss: 0.4024 - val_accuracy: 0.8350\n",
      "Epoch 89/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3576 - accuracy: 0.8487 - val_loss: 0.4006 - val_accuracy: 0.8350\n",
      "Epoch 90/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3600 - accuracy: 0.8550 - val_loss: 0.4001 - val_accuracy: 0.8350\n",
      "Epoch 91/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3587 - accuracy: 0.8525 - val_loss: 0.4023 - val_accuracy: 0.8350\n",
      "Epoch 92/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3577 - accuracy: 0.8512 - val_loss: 0.4018 - val_accuracy: 0.8350\n",
      "Epoch 93/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3570 - accuracy: 0.8525 - val_loss: 0.4004 - val_accuracy: 0.8350\n",
      "Epoch 94/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3576 - accuracy: 0.8512 - val_loss: 0.3987 - val_accuracy: 0.8350\n",
      "Epoch 95/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3568 - accuracy: 0.8525 - val_loss: 0.3999 - val_accuracy: 0.8350\n",
      "Epoch 96/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3571 - accuracy: 0.8512 - val_loss: 0.4016 - val_accuracy: 0.8350\n",
      "Epoch 97/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3570 - accuracy: 0.8525 - val_loss: 0.3998 - val_accuracy: 0.8350\n",
      "Epoch 98/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3571 - accuracy: 0.8512 - val_loss: 0.4006 - val_accuracy: 0.8350\n",
      "Epoch 99/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3570 - accuracy: 0.8500 - val_loss: 0.4004 - val_accuracy: 0.8300\n",
      "Epoch 100/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3562 - accuracy: 0.8512 - val_loss: 0.4021 - val_accuracy: 0.8350\n",
      "Epoch 101/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3567 - accuracy: 0.8487 - val_loss: 0.3995 - val_accuracy: 0.8350\n",
      "Epoch 102/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3570 - accuracy: 0.8562 - val_loss: 0.4009 - val_accuracy: 0.8350\n",
      "Epoch 103/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3573 - accuracy: 0.8500 - val_loss: 0.3998 - val_accuracy: 0.8250\n",
      "Epoch 104/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3560 - accuracy: 0.8525 - val_loss: 0.3992 - val_accuracy: 0.8350\n",
      "Epoch 105/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3566 - accuracy: 0.8475 - val_loss: 0.3988 - val_accuracy: 0.8350\n",
      "Epoch 106/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3560 - accuracy: 0.8500 - val_loss: 0.3995 - val_accuracy: 0.8350\n",
      "Epoch 107/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3557 - accuracy: 0.8500 - val_loss: 0.3980 - val_accuracy: 0.8350\n",
      "Epoch 108/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3552 - accuracy: 0.8487 - val_loss: 0.3973 - val_accuracy: 0.8350\n",
      "Epoch 109/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3553 - accuracy: 0.8512 - val_loss: 0.3998 - val_accuracy: 0.8350\n",
      "Epoch 110/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3557 - accuracy: 0.8537 - val_loss: 0.3994 - val_accuracy: 0.8300\n",
      "Epoch 111/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3547 - accuracy: 0.8562 - val_loss: 0.3991 - val_accuracy: 0.8350\n",
      "Epoch 112/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3559 - accuracy: 0.8512 - val_loss: 0.3982 - val_accuracy: 0.8350\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 26us/step - loss: 0.3548 - accuracy: 0.8537 - val_loss: 0.3956 - val_accuracy: 0.8350\n",
      "Epoch 114/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3572 - accuracy: 0.8500 - val_loss: 0.3980 - val_accuracy: 0.8350\n",
      "Epoch 115/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3573 - accuracy: 0.8512 - val_loss: 0.3983 - val_accuracy: 0.8350\n",
      "Epoch 116/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3590 - accuracy: 0.8512 - val_loss: 0.3977 - val_accuracy: 0.8350\n",
      "Epoch 117/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3552 - accuracy: 0.8525 - val_loss: 0.3971 - val_accuracy: 0.8350\n",
      "Epoch 118/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3550 - accuracy: 0.8562 - val_loss: 0.3975 - val_accuracy: 0.8300\n",
      "Epoch 119/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3559 - accuracy: 0.8500 - val_loss: 0.3985 - val_accuracy: 0.8350\n",
      "Epoch 120/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3549 - accuracy: 0.8550 - val_loss: 0.3972 - val_accuracy: 0.8350\n",
      "Epoch 121/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3553 - accuracy: 0.8500 - val_loss: 0.3959 - val_accuracy: 0.8350\n",
      "Epoch 122/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3547 - accuracy: 0.8512 - val_loss: 0.3975 - val_accuracy: 0.8350\n",
      "Epoch 123/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3537 - accuracy: 0.8500 - val_loss: 0.3978 - val_accuracy: 0.8350\n",
      "Epoch 124/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3540 - accuracy: 0.8525 - val_loss: 0.3973 - val_accuracy: 0.8350\n",
      "Epoch 125/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3549 - accuracy: 0.8512 - val_loss: 0.3970 - val_accuracy: 0.8250\n",
      "Epoch 126/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3538 - accuracy: 0.8500 - val_loss: 0.3960 - val_accuracy: 0.8350\n",
      "Epoch 127/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3540 - accuracy: 0.8487 - val_loss: 0.3956 - val_accuracy: 0.8350\n",
      "Epoch 128/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3545 - accuracy: 0.8537 - val_loss: 0.3954 - val_accuracy: 0.8350\n",
      "Epoch 129/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3546 - accuracy: 0.8525 - val_loss: 0.3978 - val_accuracy: 0.8300\n",
      "Epoch 130/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3537 - accuracy: 0.8562 - val_loss: 0.3962 - val_accuracy: 0.8350\n",
      "Epoch 131/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3532 - accuracy: 0.8487 - val_loss: 0.3956 - val_accuracy: 0.8350\n",
      "Epoch 132/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3543 - accuracy: 0.8500 - val_loss: 0.3960 - val_accuracy: 0.8400\n",
      "Epoch 133/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3553 - accuracy: 0.8475 - val_loss: 0.3946 - val_accuracy: 0.8350\n",
      "Epoch 134/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3539 - accuracy: 0.8525 - val_loss: 0.3944 - val_accuracy: 0.8250\n",
      "Epoch 135/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3529 - accuracy: 0.8512 - val_loss: 0.3955 - val_accuracy: 0.8350\n",
      "Epoch 136/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3531 - accuracy: 0.8525 - val_loss: 0.3959 - val_accuracy: 0.8350\n",
      "Epoch 137/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3576 - accuracy: 0.8438 - val_loss: 0.3957 - val_accuracy: 0.8350\n",
      "Epoch 138/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3542 - accuracy: 0.8562 - val_loss: 0.3959 - val_accuracy: 0.8300\n",
      "Epoch 139/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3539 - accuracy: 0.8537 - val_loss: 0.3926 - val_accuracy: 0.8300\n",
      "Epoch 140/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3549 - accuracy: 0.8562 - val_loss: 0.3955 - val_accuracy: 0.8350\n",
      "Epoch 141/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3533 - accuracy: 0.8512 - val_loss: 0.3934 - val_accuracy: 0.8350\n",
      "Epoch 142/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3526 - accuracy: 0.8500 - val_loss: 0.3938 - val_accuracy: 0.8350\n",
      "Epoch 143/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3530 - accuracy: 0.8537 - val_loss: 0.3942 - val_accuracy: 0.8300\n",
      "Epoch 144/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3528 - accuracy: 0.8512 - val_loss: 0.3934 - val_accuracy: 0.8350\n",
      "Epoch 145/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3546 - accuracy: 0.8587 - val_loss: 0.3936 - val_accuracy: 0.8250\n",
      "Epoch 146/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3543 - accuracy: 0.8537 - val_loss: 0.3925 - val_accuracy: 0.8350\n",
      "Epoch 147/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3539 - accuracy: 0.8537 - val_loss: 0.3949 - val_accuracy: 0.8350\n",
      "Epoch 148/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3531 - accuracy: 0.8512 - val_loss: 0.3938 - val_accuracy: 0.8350\n",
      "Epoch 149/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3531 - accuracy: 0.8525 - val_loss: 0.3910 - val_accuracy: 0.8350\n",
      "Epoch 150/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3537 - accuracy: 0.8487 - val_loss: 0.3929 - val_accuracy: 0.8400\n",
      "Epoch 151/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3529 - accuracy: 0.8500 - val_loss: 0.3920 - val_accuracy: 0.8350\n",
      "Epoch 152/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3525 - accuracy: 0.8525 - val_loss: 0.3920 - val_accuracy: 0.8300\n",
      "Epoch 153/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3529 - accuracy: 0.8475 - val_loss: 0.3930 - val_accuracy: 0.8300\n",
      "Epoch 154/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3536 - accuracy: 0.8462 - val_loss: 0.3912 - val_accuracy: 0.8350\n",
      "Epoch 155/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3523 - accuracy: 0.8550 - val_loss: 0.3893 - val_accuracy: 0.8350\n",
      "Epoch 156/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3520 - accuracy: 0.8487 - val_loss: 0.3927 - val_accuracy: 0.8300\n",
      "Epoch 157/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3524 - accuracy: 0.8525 - val_loss: 0.3921 - val_accuracy: 0.8350\n",
      "Epoch 158/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3522 - accuracy: 0.8525 - val_loss: 0.3916 - val_accuracy: 0.8350\n",
      "Epoch 159/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3526 - accuracy: 0.8512 - val_loss: 0.3895 - val_accuracy: 0.8300\n",
      "Epoch 160/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3537 - accuracy: 0.8575 - val_loss: 0.3931 - val_accuracy: 0.8350\n",
      "Epoch 161/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3516 - accuracy: 0.8512 - val_loss: 0.3904 - val_accuracy: 0.8350\n",
      "Epoch 162/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3529 - accuracy: 0.8512 - val_loss: 0.3918 - val_accuracy: 0.8250\n",
      "Epoch 163/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3525 - accuracy: 0.8562 - val_loss: 0.3924 - val_accuracy: 0.8350\n",
      "Epoch 164/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3525 - accuracy: 0.8475 - val_loss: 0.3911 - val_accuracy: 0.8300\n",
      "Epoch 165/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3527 - accuracy: 0.8525 - val_loss: 0.3908 - val_accuracy: 0.8350\n",
      "Epoch 166/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3524 - accuracy: 0.8575 - val_loss: 0.3896 - val_accuracy: 0.8350\n",
      "Epoch 167/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3518 - accuracy: 0.8525 - val_loss: 0.3889 - val_accuracy: 0.8350\n",
      "Epoch 168/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3513 - accuracy: 0.8525 - val_loss: 0.3911 - val_accuracy: 0.8350\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 26us/step - loss: 0.3519 - accuracy: 0.8537 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 170/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3518 - accuracy: 0.8537 - val_loss: 0.3924 - val_accuracy: 0.8250\n",
      "Epoch 171/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3519 - accuracy: 0.8512 - val_loss: 0.3912 - val_accuracy: 0.8350\n",
      "Epoch 172/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3514 - accuracy: 0.8562 - val_loss: 0.3902 - val_accuracy: 0.8350\n",
      "Epoch 173/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3536 - accuracy: 0.8512 - val_loss: 0.3894 - val_accuracy: 0.8300\n",
      "Epoch 174/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3514 - accuracy: 0.8562 - val_loss: 0.3908 - val_accuracy: 0.8350\n",
      "Epoch 175/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3514 - accuracy: 0.8562 - val_loss: 0.3916 - val_accuracy: 0.8300\n",
      "Epoch 176/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3510 - accuracy: 0.8537 - val_loss: 0.3899 - val_accuracy: 0.8350\n",
      "Epoch 177/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3512 - accuracy: 0.8512 - val_loss: 0.3912 - val_accuracy: 0.8350\n",
      "Epoch 178/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3509 - accuracy: 0.8537 - val_loss: 0.3901 - val_accuracy: 0.8350\n",
      "Epoch 179/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3514 - accuracy: 0.8500 - val_loss: 0.3900 - val_accuracy: 0.8400\n",
      "Epoch 180/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3516 - accuracy: 0.8525 - val_loss: 0.3925 - val_accuracy: 0.8450\n",
      "Epoch 181/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3516 - accuracy: 0.8512 - val_loss: 0.3916 - val_accuracy: 0.8300\n",
      "Epoch 182/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3534 - accuracy: 0.8500 - val_loss: 0.3925 - val_accuracy: 0.8250\n",
      "Epoch 183/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3517 - accuracy: 0.8537 - val_loss: 0.3917 - val_accuracy: 0.8350\n",
      "Epoch 184/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3514 - accuracy: 0.8525 - val_loss: 0.3908 - val_accuracy: 0.8350\n",
      "Epoch 185/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3525 - accuracy: 0.8537 - val_loss: 0.3887 - val_accuracy: 0.8300\n",
      "Epoch 186/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3519 - accuracy: 0.8512 - val_loss: 0.3928 - val_accuracy: 0.8250\n",
      "Epoch 187/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3505 - accuracy: 0.8512 - val_loss: 0.3912 - val_accuracy: 0.8350\n",
      "Epoch 188/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3514 - accuracy: 0.8525 - val_loss: 0.3895 - val_accuracy: 0.8350\n",
      "Epoch 189/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3528 - accuracy: 0.8487 - val_loss: 0.3924 - val_accuracy: 0.8300\n",
      "Epoch 190/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3513 - accuracy: 0.8562 - val_loss: 0.3898 - val_accuracy: 0.8300\n",
      "Epoch 191/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3504 - accuracy: 0.8525 - val_loss: 0.3906 - val_accuracy: 0.8400\n",
      "Epoch 192/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3512 - accuracy: 0.8512 - val_loss: 0.3909 - val_accuracy: 0.8300\n",
      "Epoch 193/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3514 - accuracy: 0.8537 - val_loss: 0.3925 - val_accuracy: 0.8450\n",
      "Epoch 194/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3504 - accuracy: 0.8562 - val_loss: 0.3924 - val_accuracy: 0.8350\n",
      "Epoch 195/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3521 - accuracy: 0.8525 - val_loss: 0.3919 - val_accuracy: 0.8350\n",
      "Epoch 196/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3500 - accuracy: 0.8525 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 197/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3512 - accuracy: 0.8550 - val_loss: 0.3902 - val_accuracy: 0.8400\n",
      "Epoch 198/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3507 - accuracy: 0.8537 - val_loss: 0.3924 - val_accuracy: 0.8350\n",
      "Epoch 199/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3506 - accuracy: 0.8500 - val_loss: 0.3901 - val_accuracy: 0.8300\n",
      "Epoch 200/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3520 - accuracy: 0.8562 - val_loss: 0.3915 - val_accuracy: 0.8300\n",
      "Epoch 201/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3529 - accuracy: 0.8525 - val_loss: 0.3904 - val_accuracy: 0.8350\n",
      "Epoch 202/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3533 - accuracy: 0.8512 - val_loss: 0.3899 - val_accuracy: 0.8300\n",
      "Epoch 203/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3535 - accuracy: 0.8525 - val_loss: 0.3923 - val_accuracy: 0.8350\n",
      "Epoch 204/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3508 - accuracy: 0.8562 - val_loss: 0.3906 - val_accuracy: 0.8350\n",
      "Epoch 205/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3504 - accuracy: 0.8550 - val_loss: 0.3900 - val_accuracy: 0.8250\n",
      "Epoch 206/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3503 - accuracy: 0.8537 - val_loss: 0.3905 - val_accuracy: 0.8300\n",
      "Epoch 207/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3505 - accuracy: 0.8550 - val_loss: 0.3906 - val_accuracy: 0.8300\n",
      "Epoch 208/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3521 - accuracy: 0.8550 - val_loss: 0.3892 - val_accuracy: 0.8350\n",
      "Epoch 209/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3524 - accuracy: 0.8537 - val_loss: 0.3909 - val_accuracy: 0.8350\n",
      "Epoch 210/500\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3517 - accuracy: 0.8537 - val_loss: 0.3927 - val_accuracy: 0.8350\n",
      "Epoch 211/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3494 - accuracy: 0.8550 - val_loss: 0.3906 - val_accuracy: 0.8350\n",
      "Epoch 212/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3523 - accuracy: 0.8512 - val_loss: 0.3905 - val_accuracy: 0.8300\n",
      "Epoch 213/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3506 - accuracy: 0.8550 - val_loss: 0.3902 - val_accuracy: 0.8350\n",
      "Epoch 214/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3497 - accuracy: 0.8537 - val_loss: 0.3906 - val_accuracy: 0.8250\n",
      "Epoch 215/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3509 - accuracy: 0.8500 - val_loss: 0.3920 - val_accuracy: 0.8350\n",
      "Epoch 216/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3504 - accuracy: 0.8500 - val_loss: 0.3895 - val_accuracy: 0.8250\n",
      "Epoch 217/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3506 - accuracy: 0.8562 - val_loss: 0.3892 - val_accuracy: 0.8350\n",
      "Epoch 218/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3502 - accuracy: 0.8537 - val_loss: 0.3908 - val_accuracy: 0.8350\n",
      "Epoch 219/500\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3493 - accuracy: 0.8537 - val_loss: 0.3923 - val_accuracy: 0.8350\n",
      "Epoch 220/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3511 - accuracy: 0.8500 - val_loss: 0.3919 - val_accuracy: 0.8250\n",
      "Epoch 221/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3507 - accuracy: 0.8562 - val_loss: 0.3921 - val_accuracy: 0.8350\n",
      "Epoch 222/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3506 - accuracy: 0.8562 - val_loss: 0.3918 - val_accuracy: 0.8300\n",
      "Epoch 223/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3498 - accuracy: 0.8512 - val_loss: 0.3903 - val_accuracy: 0.8350\n",
      "Epoch 224/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3502 - accuracy: 0.8575 - val_loss: 0.3925 - val_accuracy: 0.8300\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 25us/step - loss: 0.3522 - accuracy: 0.8512 - val_loss: 0.3892 - val_accuracy: 0.8300\n",
      "Epoch 226/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3513 - accuracy: 0.8512 - val_loss: 0.3905 - val_accuracy: 0.8300\n",
      "Epoch 227/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3526 - accuracy: 0.8562 - val_loss: 0.3917 - val_accuracy: 0.8300\n",
      "Epoch 228/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3495 - accuracy: 0.8537 - val_loss: 0.3915 - val_accuracy: 0.8300\n",
      "Epoch 229/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3500 - accuracy: 0.8512 - val_loss: 0.3902 - val_accuracy: 0.8350\n",
      "Epoch 230/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3506 - accuracy: 0.8537 - val_loss: 0.3909 - val_accuracy: 0.8350\n",
      "Epoch 231/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.3926 - val_accuracy: 0.8250\n",
      "Epoch 232/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3507 - accuracy: 0.8487 - val_loss: 0.3898 - val_accuracy: 0.8300\n",
      "Epoch 233/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3511 - accuracy: 0.8537 - val_loss: 0.3925 - val_accuracy: 0.8300\n",
      "Epoch 234/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3529 - accuracy: 0.8525 - val_loss: 0.3926 - val_accuracy: 0.8250\n",
      "Epoch 235/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3505 - accuracy: 0.8550 - val_loss: 0.3884 - val_accuracy: 0.8350\n",
      "Epoch 236/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3509 - accuracy: 0.8537 - val_loss: 0.3917 - val_accuracy: 0.8350\n",
      "Epoch 237/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3511 - accuracy: 0.8525 - val_loss: 0.3892 - val_accuracy: 0.8300\n",
      "Epoch 238/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3529 - accuracy: 0.8525 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 239/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3498 - accuracy: 0.8537 - val_loss: 0.3892 - val_accuracy: 0.8350\n",
      "Epoch 240/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3498 - accuracy: 0.8525 - val_loss: 0.3906 - val_accuracy: 0.8350\n",
      "Epoch 241/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3489 - accuracy: 0.8537 - val_loss: 0.3913 - val_accuracy: 0.8250\n",
      "Epoch 242/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3495 - accuracy: 0.8550 - val_loss: 0.3923 - val_accuracy: 0.8250\n",
      "Epoch 243/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3505 - accuracy: 0.8525 - val_loss: 0.3926 - val_accuracy: 0.8450\n",
      "Epoch 244/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3520 - accuracy: 0.8550 - val_loss: 0.3919 - val_accuracy: 0.8300\n",
      "Epoch 245/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.3925 - val_accuracy: 0.8250\n",
      "Epoch 246/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3512 - accuracy: 0.8537 - val_loss: 0.3891 - val_accuracy: 0.8350\n",
      "Epoch 247/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3499 - accuracy: 0.8550 - val_loss: 0.3926 - val_accuracy: 0.8350\n",
      "Epoch 248/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3491 - accuracy: 0.8537 - val_loss: 0.3914 - val_accuracy: 0.8300\n",
      "Epoch 249/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3492 - accuracy: 0.8550 - val_loss: 0.3910 - val_accuracy: 0.8250\n",
      "Epoch 250/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3493 - accuracy: 0.8512 - val_loss: 0.3887 - val_accuracy: 0.8350\n",
      "Epoch 251/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3493 - accuracy: 0.8550 - val_loss: 0.3911 - val_accuracy: 0.8350\n",
      "Epoch 252/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3500 - accuracy: 0.8575 - val_loss: 0.3917 - val_accuracy: 0.8350\n",
      "Epoch 253/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3506 - accuracy: 0.8512 - val_loss: 0.3910 - val_accuracy: 0.8350\n",
      "Epoch 254/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3487 - accuracy: 0.8575 - val_loss: 0.3899 - val_accuracy: 0.8350\n",
      "Epoch 255/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3492 - accuracy: 0.8537 - val_loss: 0.3924 - val_accuracy: 0.8300\n",
      "Epoch 256/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3490 - accuracy: 0.8550 - val_loss: 0.3909 - val_accuracy: 0.8350\n",
      "Epoch 257/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3513 - accuracy: 0.8562 - val_loss: 0.3894 - val_accuracy: 0.8350\n",
      "Epoch 258/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3507 - accuracy: 0.8512 - val_loss: 0.3931 - val_accuracy: 0.8250\n",
      "Epoch 259/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3480 - accuracy: 0.8575 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 260/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3502 - accuracy: 0.8562 - val_loss: 0.3934 - val_accuracy: 0.8400\n",
      "Epoch 261/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3494 - accuracy: 0.8537 - val_loss: 0.3914 - val_accuracy: 0.8300\n",
      "Epoch 262/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3502 - accuracy: 0.8562 - val_loss: 0.3935 - val_accuracy: 0.8250\n",
      "Epoch 263/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3490 - accuracy: 0.8550 - val_loss: 0.3912 - val_accuracy: 0.8350\n",
      "Epoch 264/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3490 - accuracy: 0.8562 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 265/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3494 - accuracy: 0.8575 - val_loss: 0.3929 - val_accuracy: 0.8300\n",
      "Epoch 266/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3493 - accuracy: 0.8512 - val_loss: 0.3922 - val_accuracy: 0.8250\n",
      "Epoch 267/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3493 - accuracy: 0.8550 - val_loss: 0.3917 - val_accuracy: 0.8350\n",
      "Epoch 268/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3502 - accuracy: 0.8537 - val_loss: 0.3926 - val_accuracy: 0.8300\n",
      "Epoch 269/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3483 - accuracy: 0.8562 - val_loss: 0.3934 - val_accuracy: 0.8400\n",
      "Epoch 270/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3480 - accuracy: 0.8550 - val_loss: 0.3937 - val_accuracy: 0.8300\n",
      "Epoch 271/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3488 - accuracy: 0.8575 - val_loss: 0.3920 - val_accuracy: 0.8300\n",
      "Epoch 272/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.3912 - val_accuracy: 0.8400\n",
      "Epoch 273/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3492 - accuracy: 0.8587 - val_loss: 0.3920 - val_accuracy: 0.8250\n",
      "Epoch 274/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3500 - accuracy: 0.8575 - val_loss: 0.3914 - val_accuracy: 0.8350\n",
      "Epoch 275/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3495 - accuracy: 0.8537 - val_loss: 0.3946 - val_accuracy: 0.8250\n",
      "Epoch 276/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3499 - accuracy: 0.8587 - val_loss: 0.3929 - val_accuracy: 0.8350\n",
      "Epoch 277/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3481 - accuracy: 0.8562 - val_loss: 0.3914 - val_accuracy: 0.8350\n",
      "Epoch 278/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3492 - accuracy: 0.8525 - val_loss: 0.3907 - val_accuracy: 0.8300\n",
      "Epoch 279/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3497 - accuracy: 0.8587 - val_loss: 0.3917 - val_accuracy: 0.8350\n",
      "Epoch 280/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3489 - accuracy: 0.8575 - val_loss: 0.3932 - val_accuracy: 0.8350\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 24us/step - loss: 0.3481 - accuracy: 0.8550 - val_loss: 0.3940 - val_accuracy: 0.8250\n",
      "Epoch 282/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3516 - accuracy: 0.8487 - val_loss: 0.3922 - val_accuracy: 0.8350\n",
      "Epoch 283/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3484 - accuracy: 0.8600 - val_loss: 0.3936 - val_accuracy: 0.8250\n",
      "Epoch 284/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3477 - accuracy: 0.8512 - val_loss: 0.3908 - val_accuracy: 0.8300\n",
      "Epoch 285/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3478 - accuracy: 0.8550 - val_loss: 0.3935 - val_accuracy: 0.8300\n",
      "Epoch 286/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3489 - accuracy: 0.8600 - val_loss: 0.3928 - val_accuracy: 0.8350\n",
      "Epoch 287/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3486 - accuracy: 0.8562 - val_loss: 0.3924 - val_accuracy: 0.8300\n",
      "Epoch 288/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3499 - accuracy: 0.8550 - val_loss: 0.3917 - val_accuracy: 0.8300\n",
      "Epoch 289/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3485 - accuracy: 0.8487 - val_loss: 0.3925 - val_accuracy: 0.8300\n",
      "Epoch 290/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3497 - accuracy: 0.8587 - val_loss: 0.3929 - val_accuracy: 0.8350\n",
      "Epoch 291/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3480 - accuracy: 0.8525 - val_loss: 0.3927 - val_accuracy: 0.8250\n",
      "Epoch 292/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3479 - accuracy: 0.8550 - val_loss: 0.3922 - val_accuracy: 0.8300\n",
      "Epoch 293/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3486 - accuracy: 0.8587 - val_loss: 0.3909 - val_accuracy: 0.8350\n",
      "Epoch 294/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3484 - accuracy: 0.8600 - val_loss: 0.3925 - val_accuracy: 0.8300\n",
      "Epoch 295/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3479 - accuracy: 0.8600 - val_loss: 0.3932 - val_accuracy: 0.8300\n",
      "Epoch 296/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3495 - accuracy: 0.8537 - val_loss: 0.3936 - val_accuracy: 0.8350\n",
      "Epoch 297/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3474 - accuracy: 0.8575 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 298/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3486 - accuracy: 0.8525 - val_loss: 0.3915 - val_accuracy: 0.8300\n",
      "Epoch 299/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3485 - accuracy: 0.8575 - val_loss: 0.3908 - val_accuracy: 0.8350\n",
      "Epoch 300/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3480 - accuracy: 0.8575 - val_loss: 0.3920 - val_accuracy: 0.8300\n",
      "Epoch 301/500\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3501 - accuracy: 0.8575 - val_loss: 0.3919 - val_accuracy: 0.8350\n",
      "Epoch 302/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3480 - accuracy: 0.8562 - val_loss: 0.3916 - val_accuracy: 0.8350\n",
      "Epoch 303/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3482 - accuracy: 0.8587 - val_loss: 0.3915 - val_accuracy: 0.8350\n",
      "Epoch 304/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3482 - accuracy: 0.8537 - val_loss: 0.3905 - val_accuracy: 0.8300\n",
      "Epoch 305/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3477 - accuracy: 0.8562 - val_loss: 0.3936 - val_accuracy: 0.8350\n",
      "Epoch 306/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3478 - accuracy: 0.8550 - val_loss: 0.3940 - val_accuracy: 0.8300\n",
      "Epoch 307/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3476 - accuracy: 0.8550 - val_loss: 0.3919 - val_accuracy: 0.8350\n",
      "Epoch 308/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3470 - accuracy: 0.8562 - val_loss: 0.3930 - val_accuracy: 0.8300\n",
      "Epoch 309/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3467 - accuracy: 0.8600 - val_loss: 0.3921 - val_accuracy: 0.8350\n",
      "Epoch 310/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3489 - accuracy: 0.8575 - val_loss: 0.3902 - val_accuracy: 0.8300\n",
      "Epoch 311/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3475 - accuracy: 0.8587 - val_loss: 0.3923 - val_accuracy: 0.8350\n",
      "Epoch 312/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3469 - accuracy: 0.8587 - val_loss: 0.3917 - val_accuracy: 0.8300\n",
      "Epoch 313/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3471 - accuracy: 0.8562 - val_loss: 0.3931 - val_accuracy: 0.8300\n",
      "Epoch 314/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3482 - accuracy: 0.8562 - val_loss: 0.3928 - val_accuracy: 0.8350\n",
      "Epoch 315/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3498 - accuracy: 0.8550 - val_loss: 0.3921 - val_accuracy: 0.8350\n",
      "Epoch 316/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3513 - accuracy: 0.8537 - val_loss: 0.3928 - val_accuracy: 0.8250\n",
      "Epoch 317/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3478 - accuracy: 0.8525 - val_loss: 0.3928 - val_accuracy: 0.8250\n",
      "Epoch 318/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3486 - accuracy: 0.8587 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 319/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3498 - accuracy: 0.8550 - val_loss: 0.3917 - val_accuracy: 0.8300\n",
      "Epoch 320/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3490 - accuracy: 0.8587 - val_loss: 0.3903 - val_accuracy: 0.8350\n",
      "Epoch 321/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3469 - accuracy: 0.8587 - val_loss: 0.3924 - val_accuracy: 0.8300\n",
      "Epoch 322/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3474 - accuracy: 0.8500 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 323/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3479 - accuracy: 0.8600 - val_loss: 0.3926 - val_accuracy: 0.8350\n",
      "Epoch 324/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3481 - accuracy: 0.8537 - val_loss: 0.3941 - val_accuracy: 0.8250\n",
      "Epoch 325/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3470 - accuracy: 0.8550 - val_loss: 0.3919 - val_accuracy: 0.8300\n",
      "Epoch 326/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3473 - accuracy: 0.8562 - val_loss: 0.3920 - val_accuracy: 0.8350\n",
      "Epoch 327/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3467 - accuracy: 0.8575 - val_loss: 0.3927 - val_accuracy: 0.8350\n",
      "Epoch 328/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3471 - accuracy: 0.8562 - val_loss: 0.3916 - val_accuracy: 0.8350\n",
      "Epoch 329/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3475 - accuracy: 0.8575 - val_loss: 0.3930 - val_accuracy: 0.8300\n",
      "Epoch 330/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3499 - accuracy: 0.8487 - val_loss: 0.3915 - val_accuracy: 0.8300\n",
      "Epoch 331/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3474 - accuracy: 0.8587 - val_loss: 0.3943 - val_accuracy: 0.8350\n",
      "Epoch 332/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3473 - accuracy: 0.8512 - val_loss: 0.3926 - val_accuracy: 0.8250\n",
      "Epoch 333/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3465 - accuracy: 0.8587 - val_loss: 0.3925 - val_accuracy: 0.8350\n",
      "Epoch 334/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3462 - accuracy: 0.8600 - val_loss: 0.3916 - val_accuracy: 0.8350\n",
      "Epoch 335/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3475 - accuracy: 0.8562 - val_loss: 0.3904 - val_accuracy: 0.8350\n",
      "Epoch 336/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3466 - accuracy: 0.8575 - val_loss: 0.3924 - val_accuracy: 0.8350\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 25us/step - loss: 0.3482 - accuracy: 0.8575 - val_loss: 0.3938 - val_accuracy: 0.8250\n",
      "Epoch 338/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3485 - accuracy: 0.8562 - val_loss: 0.3943 - val_accuracy: 0.8450\n",
      "Epoch 339/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3473 - accuracy: 0.8537 - val_loss: 0.3951 - val_accuracy: 0.8250\n",
      "Epoch 340/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3473 - accuracy: 0.8575 - val_loss: 0.3912 - val_accuracy: 0.8300\n",
      "Epoch 341/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3472 - accuracy: 0.8537 - val_loss: 0.3953 - val_accuracy: 0.8250\n",
      "Epoch 342/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3473 - accuracy: 0.8625 - val_loss: 0.3931 - val_accuracy: 0.8350\n",
      "Epoch 343/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3473 - accuracy: 0.8587 - val_loss: 0.3913 - val_accuracy: 0.8350\n",
      "Epoch 344/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3472 - accuracy: 0.8575 - val_loss: 0.3914 - val_accuracy: 0.8350\n",
      "Epoch 345/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3468 - accuracy: 0.8525 - val_loss: 0.3940 - val_accuracy: 0.8250\n",
      "Epoch 346/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3475 - accuracy: 0.8550 - val_loss: 0.3922 - val_accuracy: 0.8350\n",
      "Epoch 347/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3457 - accuracy: 0.8562 - val_loss: 0.3934 - val_accuracy: 0.8300\n",
      "Epoch 348/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3467 - accuracy: 0.8600 - val_loss: 0.3916 - val_accuracy: 0.8350\n",
      "Epoch 349/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3474 - accuracy: 0.8575 - val_loss: 0.3927 - val_accuracy: 0.8350\n",
      "Epoch 350/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3466 - accuracy: 0.8562 - val_loss: 0.3928 - val_accuracy: 0.8300\n",
      "Epoch 351/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3471 - accuracy: 0.8575 - val_loss: 0.3918 - val_accuracy: 0.8350\n",
      "Epoch 352/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3469 - accuracy: 0.8562 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 353/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3483 - accuracy: 0.8550 - val_loss: 0.3933 - val_accuracy: 0.8450\n",
      "Epoch 354/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3486 - accuracy: 0.8512 - val_loss: 0.3925 - val_accuracy: 0.8250\n",
      "Epoch 355/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3460 - accuracy: 0.8575 - val_loss: 0.3949 - val_accuracy: 0.8350\n",
      "Epoch 356/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3465 - accuracy: 0.8587 - val_loss: 0.3924 - val_accuracy: 0.8350\n",
      "Epoch 357/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3466 - accuracy: 0.8537 - val_loss: 0.3927 - val_accuracy: 0.8300\n",
      "Epoch 358/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3468 - accuracy: 0.8575 - val_loss: 0.3939 - val_accuracy: 0.8250\n",
      "Epoch 359/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3461 - accuracy: 0.8562 - val_loss: 0.3928 - val_accuracy: 0.8350\n",
      "Epoch 360/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3472 - accuracy: 0.8562 - val_loss: 0.3937 - val_accuracy: 0.8250\n",
      "Epoch 361/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3463 - accuracy: 0.8562 - val_loss: 0.3925 - val_accuracy: 0.8350\n",
      "Epoch 362/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3464 - accuracy: 0.8562 - val_loss: 0.3919 - val_accuracy: 0.8300\n",
      "Epoch 363/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3478 - accuracy: 0.8512 - val_loss: 0.3940 - val_accuracy: 0.8250\n",
      "Epoch 364/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3473 - accuracy: 0.8562 - val_loss: 0.3934 - val_accuracy: 0.8350\n",
      "Epoch 365/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3462 - accuracy: 0.8562 - val_loss: 0.3934 - val_accuracy: 0.8300\n",
      "Epoch 366/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3474 - accuracy: 0.8575 - val_loss: 0.3937 - val_accuracy: 0.8300\n",
      "Epoch 367/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3480 - accuracy: 0.8550 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 368/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3468 - accuracy: 0.8587 - val_loss: 0.3927 - val_accuracy: 0.8300\n",
      "Epoch 369/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3474 - accuracy: 0.8550 - val_loss: 0.3951 - val_accuracy: 0.8300\n",
      "Epoch 370/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3469 - accuracy: 0.8587 - val_loss: 0.3938 - val_accuracy: 0.8300\n",
      "Epoch 371/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3464 - accuracy: 0.8562 - val_loss: 0.3933 - val_accuracy: 0.8350\n",
      "Epoch 372/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3462 - accuracy: 0.8575 - val_loss: 0.3940 - val_accuracy: 0.8250\n",
      "Epoch 373/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3464 - accuracy: 0.8550 - val_loss: 0.3932 - val_accuracy: 0.8300\n",
      "Epoch 374/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3459 - accuracy: 0.8550 - val_loss: 0.3933 - val_accuracy: 0.8350\n",
      "Epoch 375/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3462 - accuracy: 0.8587 - val_loss: 0.3936 - val_accuracy: 0.8350\n",
      "Epoch 376/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3472 - accuracy: 0.8575 - val_loss: 0.3925 - val_accuracy: 0.8250\n",
      "Epoch 377/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3477 - accuracy: 0.8575 - val_loss: 0.3936 - val_accuracy: 0.8300\n",
      "Epoch 378/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3466 - accuracy: 0.8575 - val_loss: 0.3904 - val_accuracy: 0.8350\n",
      "Epoch 379/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3462 - accuracy: 0.8562 - val_loss: 0.3931 - val_accuracy: 0.8250\n",
      "Epoch 380/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3462 - accuracy: 0.8537 - val_loss: 0.3943 - val_accuracy: 0.8400\n",
      "Epoch 381/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3461 - accuracy: 0.8587 - val_loss: 0.3951 - val_accuracy: 0.8350\n",
      "Epoch 382/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3459 - accuracy: 0.8562 - val_loss: 0.3945 - val_accuracy: 0.8350\n",
      "Epoch 383/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3458 - accuracy: 0.8587 - val_loss: 0.3915 - val_accuracy: 0.8300\n",
      "Epoch 384/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3460 - accuracy: 0.8575 - val_loss: 0.3935 - val_accuracy: 0.8350\n",
      "Epoch 385/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3460 - accuracy: 0.8512 - val_loss: 0.3951 - val_accuracy: 0.8250\n",
      "Epoch 386/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3458 - accuracy: 0.8612 - val_loss: 0.3922 - val_accuracy: 0.8350\n",
      "Epoch 387/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3458 - accuracy: 0.8537 - val_loss: 0.3945 - val_accuracy: 0.8350\n",
      "Epoch 388/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3463 - accuracy: 0.8512 - val_loss: 0.3951 - val_accuracy: 0.8250\n",
      "Epoch 389/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3458 - accuracy: 0.8537 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 390/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3465 - accuracy: 0.8612 - val_loss: 0.3937 - val_accuracy: 0.8350\n",
      "Epoch 391/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3470 - accuracy: 0.8537 - val_loss: 0.3914 - val_accuracy: 0.8300\n",
      "Epoch 392/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3459 - accuracy: 0.8575 - val_loss: 0.3929 - val_accuracy: 0.8350\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 24us/step - loss: 0.3472 - accuracy: 0.8525 - val_loss: 0.3953 - val_accuracy: 0.8350\n",
      "Epoch 394/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3454 - accuracy: 0.8562 - val_loss: 0.3948 - val_accuracy: 0.8350\n",
      "Epoch 395/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3463 - accuracy: 0.8550 - val_loss: 0.3947 - val_accuracy: 0.8350\n",
      "Epoch 396/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3472 - accuracy: 0.8562 - val_loss: 0.3914 - val_accuracy: 0.8350\n",
      "Epoch 397/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3458 - accuracy: 0.8562 - val_loss: 0.3939 - val_accuracy: 0.8250\n",
      "Epoch 398/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3457 - accuracy: 0.8550 - val_loss: 0.3929 - val_accuracy: 0.8350\n",
      "Epoch 399/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3478 - accuracy: 0.8600 - val_loss: 0.3935 - val_accuracy: 0.8300\n",
      "Epoch 400/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3465 - accuracy: 0.8562 - val_loss: 0.3933 - val_accuracy: 0.8350\n",
      "Epoch 401/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3453 - accuracy: 0.8537 - val_loss: 0.3947 - val_accuracy: 0.8250\n",
      "Epoch 402/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3458 - accuracy: 0.8562 - val_loss: 0.3955 - val_accuracy: 0.8250\n",
      "Epoch 403/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3481 - accuracy: 0.8587 - val_loss: 0.3954 - val_accuracy: 0.8400\n",
      "Epoch 404/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3462 - accuracy: 0.8575 - val_loss: 0.3943 - val_accuracy: 0.8300\n",
      "Epoch 405/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3477 - accuracy: 0.8562 - val_loss: 0.3933 - val_accuracy: 0.8350\n",
      "Epoch 406/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3467 - accuracy: 0.8512 - val_loss: 0.3930 - val_accuracy: 0.8350\n",
      "Epoch 407/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3452 - accuracy: 0.8600 - val_loss: 0.3923 - val_accuracy: 0.8350\n",
      "Epoch 408/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3470 - accuracy: 0.8525 - val_loss: 0.3961 - val_accuracy: 0.8250\n",
      "Epoch 409/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3468 - accuracy: 0.8600 - val_loss: 0.3956 - val_accuracy: 0.8350\n",
      "Epoch 410/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3468 - accuracy: 0.8575 - val_loss: 0.3946 - val_accuracy: 0.8350\n",
      "Epoch 411/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3455 - accuracy: 0.8562 - val_loss: 0.3928 - val_accuracy: 0.8350\n",
      "Epoch 412/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3459 - accuracy: 0.8550 - val_loss: 0.3928 - val_accuracy: 0.8350\n",
      "Epoch 413/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3459 - accuracy: 0.8550 - val_loss: 0.3939 - val_accuracy: 0.8350\n",
      "Epoch 414/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3467 - accuracy: 0.8562 - val_loss: 0.3969 - val_accuracy: 0.8400\n",
      "Epoch 415/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3461 - accuracy: 0.8550 - val_loss: 0.3951 - val_accuracy: 0.8250\n",
      "Epoch 416/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3462 - accuracy: 0.8550 - val_loss: 0.3944 - val_accuracy: 0.8300\n",
      "Epoch 417/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3456 - accuracy: 0.8575 - val_loss: 0.3937 - val_accuracy: 0.8350\n",
      "Epoch 418/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3462 - accuracy: 0.8562 - val_loss: 0.3954 - val_accuracy: 0.8300\n",
      "Epoch 419/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3463 - accuracy: 0.8500 - val_loss: 0.3943 - val_accuracy: 0.8300\n",
      "Epoch 420/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3453 - accuracy: 0.8612 - val_loss: 0.3968 - val_accuracy: 0.8350\n",
      "Epoch 421/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3455 - accuracy: 0.8600 - val_loss: 0.3946 - val_accuracy: 0.8300\n",
      "Epoch 422/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3454 - accuracy: 0.8600 - val_loss: 0.3955 - val_accuracy: 0.8300\n",
      "Epoch 423/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3452 - accuracy: 0.8562 - val_loss: 0.3966 - val_accuracy: 0.8300\n",
      "Epoch 424/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3442 - accuracy: 0.8575 - val_loss: 0.3955 - val_accuracy: 0.8300\n",
      "Epoch 425/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3461 - accuracy: 0.8562 - val_loss: 0.3966 - val_accuracy: 0.8300\n",
      "Epoch 426/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3445 - accuracy: 0.8600 - val_loss: 0.3948 - val_accuracy: 0.8350\n",
      "Epoch 427/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3449 - accuracy: 0.8562 - val_loss: 0.3966 - val_accuracy: 0.8300\n",
      "Epoch 428/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3448 - accuracy: 0.8612 - val_loss: 0.3959 - val_accuracy: 0.8300\n",
      "Epoch 429/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3451 - accuracy: 0.8575 - val_loss: 0.3957 - val_accuracy: 0.8300\n",
      "Epoch 430/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3471 - accuracy: 0.8575 - val_loss: 0.3959 - val_accuracy: 0.8350\n",
      "Epoch 431/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3455 - accuracy: 0.8575 - val_loss: 0.3962 - val_accuracy: 0.8300\n",
      "Epoch 432/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3463 - accuracy: 0.8550 - val_loss: 0.3957 - val_accuracy: 0.8300\n",
      "Epoch 433/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3446 - accuracy: 0.8550 - val_loss: 0.3960 - val_accuracy: 0.8350\n",
      "Epoch 434/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3461 - accuracy: 0.8600 - val_loss: 0.3958 - val_accuracy: 0.8250\n",
      "Epoch 435/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3447 - accuracy: 0.8575 - val_loss: 0.3951 - val_accuracy: 0.8350\n",
      "Epoch 436/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3451 - accuracy: 0.8600 - val_loss: 0.3977 - val_accuracy: 0.8300\n",
      "Epoch 437/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3450 - accuracy: 0.8550 - val_loss: 0.3948 - val_accuracy: 0.8300\n",
      "Epoch 438/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3461 - accuracy: 0.8587 - val_loss: 0.3963 - val_accuracy: 0.8300\n",
      "Epoch 439/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3454 - accuracy: 0.8562 - val_loss: 0.3940 - val_accuracy: 0.8350\n",
      "Epoch 440/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3453 - accuracy: 0.8562 - val_loss: 0.3951 - val_accuracy: 0.8300\n",
      "Epoch 441/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3455 - accuracy: 0.8587 - val_loss: 0.3961 - val_accuracy: 0.8300\n",
      "Epoch 442/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3445 - accuracy: 0.8600 - val_loss: 0.3962 - val_accuracy: 0.8300\n",
      "Epoch 443/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3450 - accuracy: 0.8612 - val_loss: 0.3944 - val_accuracy: 0.8350\n",
      "Epoch 444/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3449 - accuracy: 0.8562 - val_loss: 0.3968 - val_accuracy: 0.8300\n",
      "Epoch 445/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3447 - accuracy: 0.8587 - val_loss: 0.3939 - val_accuracy: 0.8300\n",
      "Epoch 446/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3452 - accuracy: 0.8612 - val_loss: 0.3957 - val_accuracy: 0.8350\n",
      "Epoch 447/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3454 - accuracy: 0.8500 - val_loss: 0.3968 - val_accuracy: 0.8350\n",
      "Epoch 448/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3445 - accuracy: 0.8600 - val_loss: 0.3955 - val_accuracy: 0.8250\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 25us/step - loss: 0.3450 - accuracy: 0.8562 - val_loss: 0.3955 - val_accuracy: 0.8300\n",
      "Epoch 450/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3444 - accuracy: 0.8575 - val_loss: 0.3948 - val_accuracy: 0.8350\n",
      "Epoch 451/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3441 - accuracy: 0.8575 - val_loss: 0.3963 - val_accuracy: 0.8300\n",
      "Epoch 452/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3444 - accuracy: 0.8587 - val_loss: 0.3962 - val_accuracy: 0.8250\n",
      "Epoch 453/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3448 - accuracy: 0.8612 - val_loss: 0.3971 - val_accuracy: 0.8350\n",
      "Epoch 454/500\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.3452 - accuracy: 0.8575 - val_loss: 0.3964 - val_accuracy: 0.8300\n",
      "Epoch 455/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3457 - accuracy: 0.8575 - val_loss: 0.3961 - val_accuracy: 0.8250\n",
      "Epoch 456/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3447 - accuracy: 0.8575 - val_loss: 0.3975 - val_accuracy: 0.8350\n",
      "Epoch 457/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3449 - accuracy: 0.8550 - val_loss: 0.3960 - val_accuracy: 0.8300\n",
      "Epoch 458/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3442 - accuracy: 0.8537 - val_loss: 0.3971 - val_accuracy: 0.8250\n",
      "Epoch 459/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3452 - accuracy: 0.8587 - val_loss: 0.3946 - val_accuracy: 0.8400\n",
      "Epoch 460/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3445 - accuracy: 0.8587 - val_loss: 0.3952 - val_accuracy: 0.8350\n",
      "Epoch 461/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3442 - accuracy: 0.8575 - val_loss: 0.3963 - val_accuracy: 0.8250\n",
      "Epoch 462/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3461 - accuracy: 0.8512 - val_loss: 0.3972 - val_accuracy: 0.8250\n",
      "Epoch 463/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3446 - accuracy: 0.8587 - val_loss: 0.3964 - val_accuracy: 0.8300\n",
      "Epoch 464/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3444 - accuracy: 0.8575 - val_loss: 0.3979 - val_accuracy: 0.8300\n",
      "Epoch 465/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3491 - accuracy: 0.8512 - val_loss: 0.3981 - val_accuracy: 0.8450\n",
      "Epoch 466/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3466 - accuracy: 0.8512 - val_loss: 0.3978 - val_accuracy: 0.8350\n",
      "Epoch 467/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3450 - accuracy: 0.8575 - val_loss: 0.3968 - val_accuracy: 0.8350\n",
      "Epoch 468/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3437 - accuracy: 0.8587 - val_loss: 0.3963 - val_accuracy: 0.8350\n",
      "Epoch 469/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3440 - accuracy: 0.8575 - val_loss: 0.3971 - val_accuracy: 0.8300\n",
      "Epoch 470/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3455 - accuracy: 0.8562 - val_loss: 0.3958 - val_accuracy: 0.8250\n",
      "Epoch 471/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3457 - accuracy: 0.8575 - val_loss: 0.3961 - val_accuracy: 0.8300\n",
      "Epoch 472/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3453 - accuracy: 0.8575 - val_loss: 0.3972 - val_accuracy: 0.8250\n",
      "Epoch 473/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3459 - accuracy: 0.8562 - val_loss: 0.3961 - val_accuracy: 0.8350\n",
      "Epoch 474/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3440 - accuracy: 0.8575 - val_loss: 0.3969 - val_accuracy: 0.8350\n",
      "Epoch 475/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3463 - accuracy: 0.8587 - val_loss: 0.3975 - val_accuracy: 0.8300\n",
      "Epoch 476/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3442 - accuracy: 0.8562 - val_loss: 0.3946 - val_accuracy: 0.8350\n",
      "Epoch 477/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3440 - accuracy: 0.8587 - val_loss: 0.3969 - val_accuracy: 0.8300\n",
      "Epoch 478/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3435 - accuracy: 0.8587 - val_loss: 0.3978 - val_accuracy: 0.8350\n",
      "Epoch 479/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3443 - accuracy: 0.8587 - val_loss: 0.3994 - val_accuracy: 0.8250\n",
      "Epoch 480/500\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.3456 - accuracy: 0.8525 - val_loss: 0.3971 - val_accuracy: 0.8250\n",
      "Epoch 481/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3468 - accuracy: 0.8612 - val_loss: 0.3976 - val_accuracy: 0.8350\n",
      "Epoch 482/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3438 - accuracy: 0.8575 - val_loss: 0.3963 - val_accuracy: 0.8350\n",
      "Epoch 483/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3440 - accuracy: 0.8587 - val_loss: 0.3978 - val_accuracy: 0.8250\n",
      "Epoch 484/500\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.3451 - accuracy: 0.8562 - val_loss: 0.3980 - val_accuracy: 0.8300\n",
      "Epoch 485/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3460 - accuracy: 0.8550 - val_loss: 0.3999 - val_accuracy: 0.8250\n",
      "Epoch 486/500\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.3449 - accuracy: 0.8550 - val_loss: 0.3972 - val_accuracy: 0.8300\n",
      "Epoch 487/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3441 - accuracy: 0.8600 - val_loss: 0.3956 - val_accuracy: 0.8350\n",
      "Epoch 488/500\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.3441 - accuracy: 0.8587 - val_loss: 0.3958 - val_accuracy: 0.8300\n",
      "Epoch 489/500\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.3443 - accuracy: 0.8575 - val_loss: 0.3972 - val_accuracy: 0.8350\n",
      "Epoch 490/500\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.3456 - accuracy: 0.8525 - val_loss: 0.3988 - val_accuracy: 0.8200\n",
      "Epoch 491/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3436 - accuracy: 0.8575 - val_loss: 0.3960 - val_accuracy: 0.8350\n",
      "Epoch 492/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3436 - accuracy: 0.8587 - val_loss: 0.3974 - val_accuracy: 0.8300\n",
      "Epoch 493/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3441 - accuracy: 0.8575 - val_loss: 0.3978 - val_accuracy: 0.8300\n",
      "Epoch 494/500\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3446 - accuracy: 0.8562 - val_loss: 0.3968 - val_accuracy: 0.8250\n",
      "Epoch 495/500\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.3454 - accuracy: 0.8587 - val_loss: 0.3977 - val_accuracy: 0.8300\n",
      "Epoch 496/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3433 - accuracy: 0.8625 - val_loss: 0.3975 - val_accuracy: 0.8350\n",
      "Epoch 497/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3436 - accuracy: 0.8600 - val_loss: 0.3971 - val_accuracy: 0.8300\n",
      "Epoch 498/500\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.3996 - val_accuracy: 0.8300\n",
      "Epoch 499/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3472 - accuracy: 0.8537 - val_loss: 0.3977 - val_accuracy: 0.8300\n",
      "Epoch 500/500\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.3451 - accuracy: 0.8500 - val_loss: 0.3983 - val_accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.854, Test: 0.820\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves of model accuracy\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning] *",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
